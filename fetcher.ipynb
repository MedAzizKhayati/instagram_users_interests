{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Query User ID:</u> 17841458726840626\n",
    "```ts\n",
    "GET {USER-ID}?fields=business_discovery.username(asasjostromphotography){\n",
    "    name,\n",
    "    ...\n",
    "    media{\n",
    "        media_url,\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "    <u><strong>In order to get USER-ID:</strong></u>\n",
    "    <ol>\n",
    "        <li>GET me/accounts</li>\n",
    "        <li>Click on the page ID</li>\n",
    "        <li>Query for instagram_business_account</li>\n",
    "        <li>That will give you the USER-ID</li>\n",
    "    <ol>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "    <u><strong>Notes:</strong></u>\n",
    "    <ul>\n",
    "        <li>By default, the API will return 25 media objects. You can use the \"limit\" parameter to get more media objects.</li>\n",
    "        <li>To get the next page of media objects, use the \"after\" parameter.</li>\n",
    "        <li>The \"after\" parameter is the cursor value returned in the \"page_info\" object of the previous response.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"https://graph.facebook.com/v16.0/\"\n",
    "TOKEN = \"EAANx1LUJPcYBAECAThWYdG9iRPJdR182r6UswLh9OWZAyAXACKs18MhJjEu2c9iA9fuoTTYEhuFBn0mwdGjE5n87bF3RqnwOdJWeZAZAlTzEfGhqgII4fuNNgtbBSeGTz7KD2iVkuZBqRqtN6cLfazSok8mmmYp33TOuzzjdFCfRCMp2RiJ3OIfFiLN4GtXD1f6JlU8FLaG3THQrfdOt\"\n",
    "IG_ACCOUNT_ID = \"17841458726840626\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename=\"dataset.json\"):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def save(dataset, filename=\"updated_dataset.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(caption):\n",
    "    return list(map(lambda word: word[1:], [word for word in caption.split() if word.startswith(\"#\") and len(word) > 1]))\n",
    "\n",
    "\n",
    "def get_instagram_user_details(username, limit=200):\n",
    "    url = f\"\"\"{HOST}{IG_ACCOUNT_ID}?fields=\n",
    "    business_discovery.username({username}){{\n",
    "        name,\n",
    "        biography,\n",
    "        followers_count,\n",
    "        follows_count,\n",
    "        media_count,\n",
    "        profile_picture_url,\n",
    "        media.limit({limit}){{\n",
    "            media_type,\n",
    "            media_url,\n",
    "            timestamp,\n",
    "            caption,\n",
    "            comments_count,\n",
    "            like_count\n",
    "        }}}}\n",
    "        &access_token={TOKEN}\"\"\"\n",
    "    url = url.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(old_dataset, fail_limit=25, start_username=None, skip_users=[]):\n",
    "    skip_users = set(skip_users)\n",
    "    errored_users = []\n",
    "    new_dataset = {}\n",
    "    fail_counter = 0\n",
    "    should_start = False if start_username else True\n",
    "    for username, value in old_dataset.items():\n",
    "        if not should_start and username == start_username:\n",
    "            should_start = True\n",
    "            continue\n",
    "        elif not should_start:\n",
    "            continue\n",
    "        if username in skip_users:\n",
    "            continue\n",
    "        interests = value[\"interests\"]\n",
    "        business_category_name = value[\"business_category_name\"]\n",
    "        details = get_instagram_user_details(username)\n",
    "        try:\n",
    "            details = details[\"business_discovery\"]\n",
    "            details[\"business_category_name\"] = business_category_name\n",
    "            details[\"interests\"] = interests\n",
    "            details[\"posts\"] = {}\n",
    "            for post in details[\"media\"][\"data\"]:\n",
    "                post[\"hashtags\"] = extract_hashtags(post.get(\"caption\", \"\"))\n",
    "                details[\"posts\"][post[\"id\"]] = post\n",
    "                del post['id']\n",
    "            del details[\"media\"]\n",
    "            new_dataset[username] = details\n",
    "            print(\n",
    "                f\"Updated {username} and found {len(details['posts'])} posts\")\n",
    "            fail_counter = 0\n",
    "        except Exception as e:\n",
    "            errored_users.append(username)\n",
    "            print(f\"Error for {username}: {e}, {details['error']['message']}\")\n",
    "            fail_counter += 1\n",
    "            if fail_counter == fail_limit:\n",
    "                print(f\"Failed to fetch {fail_counter} users, stopping...\")\n",
    "                break\n",
    "            continue\n",
    "    return new_dataset, errored_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last username: gopro\n",
      "Number of instances in new dataset: 264\n"
     ]
    }
   ],
   "source": [
    "old_dataset = read_dataset(\"dataset.json\")\n",
    "# get latest username \n",
    "updated_dataset = read_dataset(\"updated_dataset.json\")\n",
    "last_username = list(updated_dataset.keys())[-1]\n",
    "print(f\"Last username: {last_username}\")\n",
    "old_errored_users = read_dataset(\"errored_users.json\")\n",
    "print(f'Number of instances in new dataset: {len(updated_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch completed with 0 successful accounts and 0 errors.\n"
     ]
    }
   ],
   "source": [
    "skip_users = [*old_errored_users, *updated_dataset.keys()]\n",
    "new_dataset, errored_users = update_dataset(old_dataset, skip_users=skip_users)\n",
    "print(\n",
    "    f'Fetch completed with {len(new_dataset)} successful '\n",
    "    f'accounts and {len(errored_users)} errors.'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = {**updated_dataset, **new_dataset}\n",
    "save(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "errored_users = list(set(old_errored_users + errored_users))\n",
    "save(errored_users, filename=\"errored_users.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
